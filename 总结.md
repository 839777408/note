---
title: 总结
categories:
  - 面试
tags:
  - 面试
top_img: 'https://cdn.jsdelivr.net/gh/839777408/tupian/img/wp8.jpg'
cover: 'https://cdn.jsdelivr.net/gh/839777408/tupian/img/wp8.jpg'
abbrlink: 38577
date: 2022-05-02 23:39:14
updated: 2022-5-8 22:41:11
---

# Java

## ArrayList和LinkedList的区别

>1. **是否保证线程安全：** `ArrayList` 和 `LinkedList` 都是不同步的，也就是不保证线程安全；
>2. **底层数据结构：** `Arraylist` 底层是 **`Object` 数组**；`LinkedList` 底层是 **双向链表** 数据结构
>3. **插入和删除是否受元素位置的影响：** ① **`ArrayList` 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。** 比如：执行`add(E e)`方法的时候， `ArrayList` 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（`add(int index, E element)`）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 ② **`LinkedList` 采用链表存储，所以对于`add(E e)`方法的插入，删除元素时间复杂度不受元素位置的影响，近似 O(1)，如果是要在指定位置`i`插入和删除元素的话（`(add(int index, E element)`） 时间复杂度近似为`o(n))`因为需要先移动到指定位置再插入。**
>4. **是否支持快速随机访问：** `LinkedList` 不支持高效的随机元素访问，而 `ArrayList` 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于`get(int index)`方法)。
>5. **内存空间占用：** `ArrayList` 在 list 列表的结尾会预留一定的容量空间，而 `LinkedList` 在它的每一个元素都需要消耗比 `ArrayList` 更多的空间（因为要存放前驱节点和后继节点的引用）。

## 线程池

推荐文章：[线程池原理](https://blog.csdn.net/weixin_28760063/article/details/81266152)

https://blog.csdn.net/qq_17010193/article/details/114587375?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-114587375-blog-106954169.pc_relevant_paycolumn_v3&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-114587375-blog-106954169.pc_relevant_paycolumn_v3&utm_relevant_index=1

https://blog.csdn.net/qq_36744540/article/details/118523877?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-4-118523877-blog-115555843.pc_relevant_paycolumn_v3&spm=1001.2101.3001.4242.3&utm_relevant_index=7

https://blog.csdn.net/qq_43061290/article/details/106911277?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1-106911277-blog-115555843.pc_relevant_paycolumn_v3&spm=1001.2101.3001.4242.2&utm_relevant_index=4

讲一下`ThreadPoolExecutor`的几个重要参数：

>- **`corePoolSize`:** 核心线程数，定义了最小可以同时运行的线程数量。
>- **`maximumPoolSize`:** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
>- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在任务缓存队列中。
>
>- **`keepAliveTime`:** 当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
>
>- **`unit`:** `keepAliveTime` 参数的时间单位。
>
>- **`threadFactory`:** 线程工厂，主要用来创建线程。
>
>- **`handler`:** 任务拒绝策略。

有哪几种任务缓存队列：

>- `ArrayBlockingQueue`：是一个基于数组结构的有界阻塞队列，此队列按照先进先出原则对元素进行排序
>- `LinkedBlockingQueue`：是一个基于链表结构的阻塞队列，此队列按照先进先出排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool使用了这个队列。
>- `SynchronousQueue` ：一个不存储元素的阻塞队列，每个插入操作必须等到另外一个线程调用移除操作，否则插入操作一直处理阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用这个队列


有哪几种任务拒绝策略：

>- **`ThreadPoolExecutor.AbortPolicy`：** 丢弃任务并抛出 `RejectedExecutionException`异常。
>
>- **`ThreadPoolExecutor.DiscardPolicy`：** 也是丢弃任务，但是不抛出异常。
>
>- **`ThreadPoolExecutor.DiscardOldestPolicy`：** 丢弃队列最前面的任务，然后重新尝试执行任务
>- **`ThreadPoolExecutor.CallerRunsPolicy`：** 由调用`execute`方法的线程运行被拒绝的任务 

## JDK动态代理和Cglib

# Spring

## **Spring的IoC理解**

>（1）什么是IOC：
>
>IOC，Inversion of Control，控制反转，指将对象的控制权转移给Spring框架，由 Spring 来负责控制对象的生命周期（比如创建、销毁）和对象间的依赖关系。
>
>（2）什么是DI：
>
>​    IoC 的一个重点就是在程序运行时，动态的向某个对象提供它所需要的其他对象，这一点是通过DI（Dependency Injection，依赖注入）来实现的，即应用程序在运行时依赖 IoC 容器来动态注入对象所需要的外部依赖。而 Spring 的 DI 具体就是通过反射实现注入的，反射允许程序在运行的时候动态的生成对象、执行对象的方法、改变对象的属性。

## **Spring基于xml依赖注入四种方式**

推荐文章：[Spring中bean的注入方式](https://blog.csdn.net/a745233700/article/details/89307518)

> - 构造器注入
>
> - set方法注入
>
> - 静态工厂注入
>
> - 实例工厂注入
>
> **注意：一般答前两种**

## **Spring的自动装配**

推荐文章：[Spring中的@Autowired自动装配](https://blog.csdn.net/weixin_38192427/article/details/108610810)

>自动装配也就是 Spring 会在容器中自动的查找，并自动的给 bean 装配及其关联的属性
>
>Spring **基于XML**提供了 5 种自动装配策略：
>
>- no：默认的方式是不进行自动装配的，通过手工设置ref属性来进行装配bean。
>- byName：通过bean的名称进行自动装配。
>- byType：通过参数的数据类型进行自动装配。
>- constructor：利用构造函数进行装配，并且构造函数的参数通过byType进行装配。
>- autodetect：自动探测，如果有构造方法，通过 construct的方式自动装配，否则使用byType的方式自动装配。 `Spring 3.0` 之后已经被标记为 `@Deprecated`
>
>Spring**基于注解**的自动装配方式：
>
>使用@Autowired、@Resourc或者@Inject注解来自动装配指定的bean。
>
>- @Autowired默认是`byType` 装配注入的，默认情况下它要求依赖对象必须存在（可以设置它required属性为false）。如果匹配到类型的多个实例，再通过 `byName` 来确定 bean。可以使用@Qualifier来指定注入哪个beanName的bean。
>
>-  @Resource默认是 `byName` 来装配注入的，只有当找不到与名称匹配的bean才会`byType` 来装配注入。
>- @Inject也是`byType` 来查找bean注入的，如果需要指定名称beanName，则可以结合使用@Named注解，而@Autowired是结合@Qualifier注解来指定名称beanName。
>

## **bean的生命周期**

推荐文章：可以先参考[Spring 了解Bean的一生(生命周期)](https://xulinjie.blog.csdn.net/article/details/80086950?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.pc_relevant_default&utm_relevant_index=5)，再参考[Spring的Bean加载流程](https://blog.csdn.net/a745233700/article/details/113840727)

![](https://cdn.jsdelivr.net/gh/839777408/tupian/blog2/20220422002324.png)

>（1）实例化Bean：
>
>- 对于BeanFactory容器，当客户向容器请求一个尚未初始化的bean时，或初始化bean的时候需要注入另一个尚未初始化的依赖时，容器就会调用createBean进行实例化。
>
>- 对于ApplicationContext容器，当容器启动结束后，通过获取BeanDefinition对象中的信息，实例化所有的bean。
>
>（2）设置对象属性（依赖注入）：实例化后的对象被封装在BeanWrapper对象中，紧接着，Spring根据BeanDefinition中的信息以及通过BeanWrapper提供的设置属性的接口完成属性设置与依赖注入。
>
>（3）处理Aware接口：Spring会检测该对象是否实现了xxxAware接口，通过Aware类型的接口，可以让我们拿到Spring容器的一些资源：
>
>- 如果这个Bean实现了BeanNameAware接口，会调用它实现的setBeanName(String beanId)方法，传入Bean的名字；
>- 如果这个Bean实现了BeanClassLoaderAware接口，调用setBeanClassLoader()方法，传入ClassLoader对象的实例。
>- 如果这个Bean实现了BeanFactoryAware接口，会调用它实现的setBeanFactory()方法，传递的是Spring工厂自身。
>- 如果这个Bean实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，传入Spring上下文；
>
>（4）BeanPostProcessor前置处理：如果想对Bean进行一些自定义的前置处理，那么可以让Bean实现了BeanPostProcessor接口，那将会调用postProcessBeforeInitialization(Object obj, String s)方法。
>
>（5）InitializingBean：如果Bean实现了InitializingBean接口，执行afeterPropertiesSet()方法。
>
>（6）init-method：如果Bean在Spring配置文件中配置了 init-method 属性，则会自动调用其配置的初始化方法。
>
>（7）BeanPostProcessor后置处理：如果这个Bean实现了BeanPostProcessor接口，将会调用postProcessAfterInitialization(Object obj, String s)方法；由于这个方法是在Bean初始化结束时调用的，所以可以被应用于内存或缓存技术；
>
>以上几个步骤完成后，Bean就已经被正确创建了，之后就可以使用这个Bean了。
>
>（8）DisposableBean：当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用其实现的destroy()方法；
>
>（9）destroy-method：最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法。
>

## **如何解决循环依赖**

>
>
>

# Mybatis

## **什么是SqlSession**

>SqlSession是mybatis框架中的一个对象，类似JDBC的Connection对象，是Java程序端和数据库之间的会话。
>框架底层通过sqlSession对象去执行sql语句，帮助我们实现增删改查操作

## **#{}和${}的区别**

> `#{}`底层采用的是`?占位符赋值`的方式，调用PreparedStatement的set方法来赋值，`可以对SQL语句预编译`。
>
> `${}`底层采用的是`字符串拼接sql`的方式，`容易产生sql注入`，如果需要一些`字段名或者关键字(比如order by)可以用${}`。

## **MyBatis的缓存机制**

>作用：减少web应用和数据库(磁盘)访问次数，提高查询效率，减轻数据库访问压力。
>
>一级缓存（默认级别）：
>
>是**SqlSession级别**的缓存，作用域是同一个SqlSession，在同一个sqlSession中两次执行相同的sql语句（包括参数相同），第一次执行完毕会将数据库中查询结果写到缓存，第二次会直接从缓存中获取数据，从而提高查询效率。
>
>当SqlSession执行了DML操作（增删改），**并且提交**到数据库，MyBatis则会清空SqlSession中的一级缓存，避免出现脏读。当一个 SqlSession结束后，该SqlSession中的一级缓存也就不存在了。
>
>二级缓存：
>
>是**mapper级别**的缓存，其作用域是mapper的同一个namespace，两次执行相同namespace下的sql语句（包括参数相同），第一次执行完毕会将数据库中查询结果写到缓存，第二次会从缓存中获取数据将不再从数据库查询，从而提高查询效率。
>
>mapper文件中增加标签，实体类实现序列化。
>当执行了增删改操作，清空当前sql所对应的namespace的缓存。

## **MyBatis和Mybatis-Plus的区别**

>Mybatis-Plus是无侵入的，只对Mybatis做了增强不做改变。
>
>- 内置通用 Mapper、Service，仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求
>
>- 支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错。
>
>- 支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题。
>
>- 内置代码生成器、内置分页插件
>
>- 内置性能分析插件：可输出 Sql 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询。
>
>- 内置全局拦截插件：提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防误操作。

# Mysql

## 脏读、不可重复读、幻读

推荐文章：[数据库事务隔离级别（脏读、幻读、不可重复读）](https://blog.csdn.net/qq_41776884/article/details/81608777)

>- **脏读（Dirty read）:** 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。
>- **不可重复读（Unrepeatable read）:** 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
>- **幻读（Phantom read）:** 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。
>

## 事务的隔离级别

>|          隔离级别           | 脏读 | 不可重复读 | 幻读 |
>| :-------------------------: | :--: | :--------: | :--: |
>| READ-UNCOMMITTED(读未提交） |  √   |     √      |  √   |
>|  READ-COMMITTED(读已提交)   |  ×   |     √      |  √   |
>|  REPEATABLE-READ(可重复读)  |  ×   |     ×      |  √   |
>|   SERIALIZABLE(可串行化)    |  ×   |     ×      |  ×   |
>

## 索引类型

>按数据的物理存储分类，可分为聚簇索引和非聚簇索引
>
>按索引字段特性分类，可分主键索引、普通索引、唯一索引、全文索引

# Reidis

## **缓存穿透**

>缓存穿透指一个一定不存在的数据，由于**缓存未命中**这条数据，就会去查询数据库，**数据库也没有**这条数据，所以返回结果是 `null`。如果并发量大且缓存都没有命中，每次查询都请求数据库时，缓存就失去了保护后端持久层的意义，这会给持久层数据库造成很大的压力。
>
>**解决方案：**
>
>- 缓存空对象：是指在持久层没有命中的情况下，对key进行set （key,null），缓存空对象会有两个问题：
>  - value为null 不代表不**占用内存空间**，空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间，比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。
>  - 缓存层和持久层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为5分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和持久层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。
>- 布隆过滤器拦截
>  - 在访问缓存层和持久层之前，将存在的key用布隆过滤器提前保存起来，做第一层拦截，当收到一个对key请求时先用布隆过滤器验证是key否存在，如果存在再进入缓存层、持久层。可以使用bitmap做布隆过滤器。这种方法适用于数据命中不高、数据相对固定、实时性低的应用场景，代码维护较为复杂，但是缓存空间占用少。
>  - 布隆过滤器实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的**误识别率**和删除困难。

## **缓存击穿**

>当某个key在过期的瞬间，有大量的请求并发访问，这类数据一般是**热点数据**，由于**缓存过期**，会同时访问数据库来查询最新数据，**数据库有数据**并且回写缓存，会导使数据库瞬间压力过大。
>
>**解决方案：**
>
>- 分布式互斥锁，只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。
>  - 这种方案思路比较简单，但是存在一定的隐患，如果在查询数据库 + 和 重建缓存（key失效后进行了大量的计算）时间过长，也可能会存在死锁和线程池阻塞的风险，高并发情景下吞吐量会大大降低！但是这种方法能够较好地降低后端存储负载，并在一致性上做得比较好。
>- 热点Key永不过期，从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去更新缓存。
>  - 这种方案由于没有设置真正的过期时间，实际上已经不存在热点key产生的一系列危害，但是会存在数据不一致的情况，同时代码复杂度会增大。

## **缓存雪崩**

>由于缓存层承载着大量请求，有效地保护了持久层，但是如果缓存层由于某些原因不可用（**宕机**）或者大量缓存由于超时时间相同在**同一时间段**失效（大批key失效/热点数据失效），大量请求直接到达存储层，存储层压力过大导致系统雪崩。
>
>**解决方案：**
>
>- 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
>- 可以把缓存层设计成高可用的，即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务。利用sentinel或cluster实现。
>- 采用多级缓存，本地进程作为一级缓存，redis作为二级缓存，不同级别的缓存设置的超时时间不同，即使某级缓存过期了，也有其他级别缓存兜底。
>- 数据加热，在正式部署之前先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。

## **过期的数据的删除策略**

> 如果假设你设置了一批 key 只能存活 1 分钟，那么 1 分钟后，Redis 是怎么对这批 key 进行删除的呢？
>
> 常用的过期数据的删除策略就两个：
>
> - **惰性删除** ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。
>
> - **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。
>
> 定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 **定期删除+惰性/懒汉式删除** 。
>
> 但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就 Out of memory 了。
>
> 怎么解决这个问题呢？答案就是：**Redis 内存淘汰机制。**

## **Redis 内存淘汰机制**

>Redis一开始有6种数据淘汰策略，4.0版本后增加2种（7和8），总共8种
>
>1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
>2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
>3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
>4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）
>5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
>6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！
>7. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
>8. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中移除最不经常使用的 key



# 动网先锋面经

Jmeter是怎么做压力测试的

JVM调优设置的参数了解么

mybatis和mybatis-Plus的区别

#{}和${}的区别

spring的依赖注入有哪几种方式

spring提供了哪些配置方式

bean如果有前后依赖顺序要怎么解决

如果一个配置依赖于另一个配置的内容，要怎么告诉spring

spring bean的生命周期

init、post..、构造方法、afterproperty等的调用顺序

订单id的生成，要保证唯一性，有什么方案

docker常用命令

maven有几个阶段

说一下Java里面的锁

重写的toString方法return一个字符串+this.toString（），可以运行么

# 迈聆面经

ArrayList和LinkedList的区别；

ArrayList基于什么情况查询有优势，它是怎样通过它的索引下标快速找到它的元素的，删除指定位置的元素是怎么做的，扩容是怎么做的。

HashMap的扩容是怎么做的。

线程池的参数有哪些，什么情况会用到它的阻塞队列，具体的策略有哪些，默认策略是哪个，阻塞队列有哪些，项目当中实际使用线程池的例子分享下，线程池的参数怎么配置比较好。

说一下Spring的IOC，注入bean的方式有哪些，set和构造器注入的区别是怎样（循环依赖）

说一下Spring的AOP，JDK动态代理和Cglib的区别，项目中用这两个应该怎么选

事务的隔离级别有哪些

Mysql的索引的数据结构有哪些，聚簇索引和非聚簇索引的区别，主键索引属于哪种


# SQL
获取sequence
//sql server
declare @tm_new_detail_id numeric(20, 0)
SELECT @tm_new_detail_id = CONVERT(numeric(20, 0), NEXT VALUE FOR db_xgfe_cm.customer_details_seq)
//SYBASE
declare @new_cust_detail_id unsigned bigint
select @new_cust_detail_id = convert(unsigned bigint, reserve_identity('customer_details_seq',1)) 


改索引：
sybase语法有些不同，alter 字段后面一定要加 null 还是 not null,默认not null
use db_crn
if not exists(select * from sysindexes where id=object_id('表名') and name='索引名')
alter table customer_usci_info_ext_hist_staging drop constraint pk_customer_usci_info_ext_hist_staging [删除主键]
drop index customer_usci_info_ext_hist_staging.icustomer_usci_info_ext_hist_staging [删除普通索引]
CREATE UNIQUE INDEX uk_customer_activity_log_pos ON db_crn.dbo.customer_activity_log_pos (seq)[新建唯一索引]
alter table customer_usci_info_ext_hist_staging add constraint pk_customer_usci_info_ext_hist_staging PRIMARY key(policy_no,client_type,cycle_date,info_ind)[新建主键]

查看表锁级别：
select lockscheme('db_crn..customer_policy')

查包含某字符串的存储过程：
select distinct object_name(id) from syscomments where id in(select id from sysobjects where type ='P') and text like '%po_client_insert_man_log%'

SQL SERVER查看不包含数字：
PATINDEX('%[0-9]%', a.name) = 0 

WITH AggregatedCPU AS (SELECT q.query_hash, SUM(count_executions * avg_cpu_time / 1000.0) AS total_cpu_millisec, SUM(count_executions * avg_cpu_time / 1000.0)/ SUM(count_executions) AS avg_cpu_millisec, MAX(rs.max_cpu_time / 1000.00) AS max_cpu_millisec, MIN(rs.min_cpu_time / 1000.00) AS min_cpu_millisec,MAX(max_logical_io_reads) max_logical_reads, COUNT(DISTINCT p.plan_id) AS number_of_distinct_plans, COUNT(DISTINCT p.query_id) AS number_of_distinct_query_ids, SUM(CASE WHEN rs.execution_type_desc='Aborted' THEN count_executions ELSE 0 END) AS Aborted_Execution_Count, SUM(CASE WHEN rs.execution_type_desc='Regular' THEN count_executions ELSE 0 END) AS Regular_Execution_Count, SUM(CASE WHEN rs.execution_type_desc='Exception' THEN count_executions ELSE 0 END) AS Exception_Execution_Count, SUM(count_executions) AS total_executions, MIN(qt.query_sql_text) AS sampled_query_text
FROM sys.query_store_query_text AS qt
JOIN sys.query_store_query AS q ON qt.query_text_id=q.query_text_id
JOIN sys.query_store_plan AS p ON q.query_id=p.query_id
JOIN sys.query_store_runtime_stats AS rs ON rs.plan_id=p.plan_id
JOIN sys.query_store_runtime_stats_interval AS rsi ON rsi.runtime_stats_interval_id=rs.runtime_stats_interval_id
WHERE rs.execution_type_desc IN ('Regular', 'Aborted', 'Exception')AND rsi.start_time>='2022-05-09 06:00:00' --AND rsi.start_time<='2021-10-28 05:00:00'
GROUP BY q.query_hash), OrderedCPU AS (SELECT query_hash, total_cpu_millisec, avg_cpu_millisec, max_cpu_millisec, min_cpu_millisec,max_logical_reads, number_of_distinct_plans, number_of_distinct_query_ids, total_executions, Aborted_Execution_Count, Regular_Execution_Count, Exception_Execution_Count, sampled_query_text, ROW_NUMBER() OVER (ORDER BY total_cpu_millisec DESC, query_hash ASC) AS RN
FROM AggregatedCPU)
SELECT OD.query_hash, OD.total_cpu_millisec, OD.avg_cpu_millisec, OD.max_cpu_millisec, OD.min_cpu_millisec,OD.max_logical_reads, OD.number_of_distinct_plans, OD.number_of_distinct_query_ids, OD.total_executions, OD.Aborted_Execution_Count, OD.Regular_Execution_Count, OD.Exception_Execution_Count, OD.sampled_query_text, OD.RN
FROM OrderedCPU AS OD
WHERE OD.RN<=100 -- and sampled_query_text like '%VS9251B%'
ORDER BY total_cpu_millisec DESC;


excel 文本类型选general  ="'" &A1&"',"
快速选择所需行，左上角输入 D2:D414716, 按住ctrl+enter，光标移到公式后，继续按住ctrl+enter
=IF((A1=B1),TRUE,FALSE)判断两列内容是否相同
=countif(B:B,C2)C列中的内容有没有在B列中出现过,结果为0的，就是B列中没有出现过的，而结果不为0，则是在B列中出现过

note pad++ 行前行尾添加字符：
1.按Ctrl + H 打开替换窗口
2.查找模式选择正则表达式
3.输入 ^  行前添加字符串
4.输入 $  行尾添加字符串
删除包含某字符串的行：.*DROP.*(正则表达式)
删除空白行：^\s


--liquibase formatted sql
--changeset 2022-05-06_1234_ASNPILN:add-trg_tatp_dus_extr_result_rtn-TRIGGER_v1 context:sit,uat stripComments:false

USE [db_bcf]
GO

IF OBJECT_ID ('dbo.trg_tatp_dus_extr_result_rtn', 'TR') IS NOT NULL
DROP TRIGGER  [dbo].[trg_tatp_dus_extr_result_rtn]
GO

SET ANSI_NULLS ON
GO

SET QUOTED_IDENTIFIER ON
GO


CREATE TRIGGER [dbo].[trg_tatp_dus_extr_result_rtn]
ON [dbo].[tatp_dus_extr_result_rtn] FOR UPDATE,INSERT,DELETE
AS
BEGIN
----
--2022/5/6 Nan add trigger
----
    declare @op varchar(10)
    select @op=case when exists(select 1 from inserted) and exists(select 1 from deleted)
                        then 'Update'
                    when exists(select 1 from inserted) and not exists(select 1 from deleted)
                        then 'Insert'
                    when not exists(select 1 from inserted) and exists(select 1 from deleted)
                        then 'Delete' end

    if @op = 'Update'
        begin
            insert into [dbo].[tatp_dus_extr_result_rtn_log]
            (file_content,spid,prog_name,user_name,hostname,ip_address,action_type,update_time)
            select file_content,
                   @@spid,
                   (select program_name as prog_name from sys.dm_exec_sessions where session_id=@@spid),
                   (select login_name as user_name from sys.dm_exec_sessions where session_id=@@spid),
                   (select hostname as hostname from sys.sysprocesses where spid=@@spid),
                   (select client_net_address as ip_address from sys.dm_exec_connections where session_id=@@spid),
                   'Before Update',
                   getdate()
            from deleted

            insert into [dbo].[tatp_dus_extr_result_rtn_log]
            (file_content,spid,prog_name,user_name,hostname,ip_address,action_type,update_time)
            select file_content,
                   @@spid,
                   (select program_name as prog_name from sys.dm_exec_sessions where session_id=@@spid),
                   (select login_name as user_name from sys.dm_exec_sessions where session_id=@@spid),
                   (select hostname as hostname from sys.sysprocesses where spid=@@spid),
                   (select client_net_address as ip_address from sys.dm_exec_connections where session_id=@@spid),
                   'After Update',
                   getdate()
            from inserted
        end
    else if @op = 'Delete'
        begin
            insert into [dbo].[tatp_dus_extr_result_rtn_log]
            (file_content,spid,prog_name,user_name,hostname,ip_address,action_type,update_time)
            select file_content,
                   @@spid,
                   (select program_name as prog_name from sys.dm_exec_sessions where session_id=@@spid),
                   (select login_name as user_name from sys.dm_exec_sessions where session_id=@@spid),
                   (select hostname as hostname from sys.sysprocesses where spid=@@spid),
                   (select client_net_address as ip_address from sys.dm_exec_connections where session_id=@@spid),
                   @op,
                   getdate()
            from deleted
        end
    else
        begin
            insert into [dbo].[tatp_dus_extr_result_rtn_log]
            (file_content,spid,prog_name,user_name,hostname,ip_address,action_type,update_time)
            select file_content,
                   @@spid,
                   (select program_name as prog_name from sys.dm_exec_sessions where session_id=@@spid),
                   (select login_name as user_name from sys.dm_exec_sessions where session_id=@@spid),
                   (select hostname as hostname from sys.sysprocesses where spid=@@spid),
                   (select client_net_address as ip_address from sys.dm_exec_connections where session_id=@@spid),
                   @op,
                   getdate()
            from inserted
        end
END
GO


--liquibase formatted sql
--changeset 2022-05-06_1234_ASNPILN:add-tatp_dus_extr_result_rtn_log-TABLE_v1 context:sit,uat

USE [db_bcf]
GO

SET ANSI_NULLS ON
GO

SET QUOTED_IDENTIFIER ON
GO

IF  exists (select * from sysobjects where type = 'U' and name = 'tatp_dus_extr_result_rtn_log')
BEGIN
drop table [dbo].[tatp_dus_extr_result_rtn_log]
END


CREATE TABLE [dbo].[tatp_dus_extr_result_rtn_log]
(
[file_content] [char](150) NOT NULL,
[spid] int NULL,
[prog_name] [varchar](100) NULL,
[user_name] [varchar](100) NULL,
[hostname] varchar(100) NULL,
[ip_address] varchar(100) NULL,
[action_type] [varchar](40)  NULL,
[update_time] [datetime]  NULL
)
GO

USE [db_crn]
GO

IF EXISTS (select * from dbo.sysobjects where id = object_id(N'[dbo].[po_client_sel_in_man_log]') and OBJECTPROPERTY(id, N'IsProcedure') = 1)
DROP PROCEDURE [dbo].[po_client_sel_in_man_log]
GO

use db_crn
GO
IF NOT EXISTS (
SELECT 1
FROM   sys.columns
WHERE  object_id = OBJECT_ID(N'[dbo].[cm_mandate_log]')
AND name = 'acct_type'
)
BEGIN
ALTER TABLE dbo.cm_mandate_log ADD acct_type char(2) NULL
END
GO